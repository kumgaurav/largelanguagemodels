{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero and Few Shot Prompting\n",
    "\n",
    "Writing good prompts for large language models is a combination of art, science and, perhaps a bit of wizardry. As you\n",
    "know, the model is a statistical one, taking numeric input sequences and creating an output sequence to match based on\n",
    "the (a) pretrained data, (b) the input sequence itself, and (c) the various parameters we can use when calling the\n",
    "model. In this lecture I want to introduce you to three different prompting strategies. I caution that there are many\n",
    "more strategies out there, but these two form a nice foundation for current practices and they work well with llama 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Prompting\n",
    "\n",
    "You've actually seen zero shot prompting many times in this course -- it's simply giving the model a single set of\n",
    "instructions to respond to, and letting the model use it's pretrained weights. And actually, calling the inputs as\n",
    "\"instructions\" is questionable at best -- many of us are use to the chat gpt conversational style, but the model is\n",
    "actually just doing output sequence prediction. So zero shot prompting is giving an input sequence and taking from the\n",
    "model a predicted appropriate output sequence.\n",
    "\n",
    "Throughout this lecture I'm going to use a really authentic task for myself -- you see, I teach a lot of programming in\n",
    "my day to day job at the University of Michigan and here on the Coursera platform. This often coveres topics in the\n",
    "areas of python, data science, and applied AI. One of the things I'd like to do is give students more quick questions to\n",
    "test their knowledge. But, coming up with good questions is difficult, and then I have to type them all out and enter\n",
    "them into a quizzing tool to be delivered to the learner. Most of these tools can take JSON formatted questions, but I\n",
    "find typing out JSON documents as slow and error prone. So let's see if we can build a conversational agent to help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup our lamma model, and this time I'm going to bump up the context\n",
    "# window a bit. This can slow things down, but also will result in more output\n",
    "# tokens being sent back to us.\n",
    "import os\n",
    "from llama_cpp import Llama\n",
    "from llama_cpp.llama_types import *\n",
    "\n",
    "model: Llama = Llama(\n",
    "    model_path=os.environ[\"LLAMA_13B\"], verbose=False, n_ctx=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'NoneType' object is not iterable\n",
      "\n",
      "I have this code for Python 3.6 and I am getting an error when I try to access the value of `lambda`:\n",
      "\n",
      "\\begin{code}\n",
      "from json import dump, dumps\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "data = {'key':[1,2], 'value':[np.nan, 5]}\n",
      "df = pd.DataFrame(data)\n",
      "# df.to_json()\n",
      "dumps(df)\n",
      "\\end{code}\n",
      "\n",
      "The error I get is:\n",
      "\n",
      "\\begin{code}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\json\\_json.py\", line 128, in <listcomp>\n",
      "    return [json_type(obj) if _is_iterable(obj) else json_value(obj) for obj in row]\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "\\end{code}\n",
      "\n",
      "I also tried this code:\n",
      "\n",
      "\\begin{code}\n",
      "import json\n",
      "json.dumps(data, indent=4)\n",
      "\\end{code}\n",
      "\n",
      "It works fine but I want to keep the line count for each column and I am getting an error when I try it on my big data set. So I tried this code:\n",
      "\n",
      "\\begin{code}\n",
      "import json\n",
      "json.dump(data, indent=4)\n",
      "\\end{code}\n",
      "\n",
      "and now I get the same error but it is not working with `dumps()` too. Is there a way to fix this?\n",
      "\n",
      "Comment: It's telling you that some of your data objects are None, and they can't be iterated over. Check which keys contain None in your dataframe.\n",
      "\n",
      "Answer: \\strong{EDIT}\n",
      "\n",
      "I think the real problem is that `np.nan` (or rather the numpy representation of it) is a Python `None`, not an object that can be JSON serialized to `\"null\"`.  In addition, when you try to write a DataFrame into JSON as a string, it will \\em{not} include any of the special attributes like [`dtype`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dtype.html) or column names; this is why it's important to use `to_json()` rather than `to_dict()`.  As [the docs](http://pandas.pydata.org/pandas-docs/stable/io.html#io-json) say:\n",
      "\n",
      "\\begin{blockquote}\n",
      "\n",
      "Note: \\strong{\\em{`df.to_json(orient='records')`}} does not preserve the `index` and `columns`. The output format is: \\strong{`[{\"key\": \"foo\", \"value\": 1}, {\"key\": \"bar\", \"value\": 2}]`}\n",
      "\\end{blockquote}\n",
      "\n",
      "If you want to write a DataFrame into JSON, you should use `to_json()` rather than `to_dict()`.  If you want the column names preserved (as well as the dtypes), then it's probably easier to just dump your entire data frame as one object with [`DataFrame.to_string()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_string.html).\n",
      "\n",
      "\\begin{code}\n",
      "df = pd.DataFrame(np.random.randn(5, 2))\n",
      "# create a DataFrame with some NaN values\n",
      "df['key'][0] = np.nan\n",
      "df['value'][4] = np.nan\n",
      "\n",
      "import json\n",
      "json.dumps(df)\n",
      "\\end{code}\n",
      "\n",
      "Output:\n",
      "\n",
      "\\begin{code}\n",
      "'{\"values\": {\"column_1\": [2.38326795, -0.10753454, 0.24442227, 0.50882634, -1.76536403], \"column_2\": [0.89209347, -0.39964681, -0.08417097, 0.88532468, 0.52200653]}, \"columns\": [\"column_1\", \"column_2\"], \"index\": [0, 1, 2, 3, 4], \"dataframe\": true}'\n",
      "\\end{code}\n",
      "\n",
      "Comment: I want to keep the line count for each column and I am getting an error when I try it on my big data set.\n",
      "\n",
      "Comment: @user3846096 I'm not sure what you mean, but if you mean the JSON output is too large, that shouldn't happen; can you edit your question to show a complete example where this happens?  It sounds like you should be using `to_json()` instead of `to_dict()` - see my update.\n",
      "\n",
      "Comment: I edited my question and added what I tried and the error I am getting when I use dumps() or dump()."
     ]
    }
   ],
   "source": [
    "# Now, in zero shot prompting we're just asking the language model to\n",
    "# continue our text it's pretrained weights. Since I want to generate\n",
    "# some python 3 lambda questions in JSON, this seems like a good\n",
    "# starting point!\n",
    "\n",
    "prompt = \"Python 3 lambda question in JSON:\"\n",
    "\n",
    "# Now let's watch the results. Remember you need to increase the\n",
    "# max_tokens as well as the context window or llama.cpp will cut\n",
    "# off the reply\n",
    "for response in model.create_completion(prompt, max_tokens=2048, stream=True):\n",
    "    result = response[\"choices\"][0]\n",
    "    print(result[\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, well, that doesn't seem like a completely unreasonable response to the prompt, but it's certainly not what I was\n",
    "looking for. Let's try another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 bytes.\n",
      "It's a bit of a tough one, but you don't need to write out the code itself. Just list the required inputs and output in the order it would be evaluated, and list the operations needed to reach that result from those inputs."
     ]
    }
   ],
   "source": [
    "# Just a little tweak, trying to write the prompt as if it were\n",
    "# something that was observed in the training data, e.g. a textbook\n",
    "prompt = \"A good Python 3 lambda question rendered in JSON is \"\n",
    "\n",
    "for response in model.create_completion(prompt, max_tokens=2048, stream=True):\n",
    "    result = response[\"choices\"][0]\n",
    "    print(result[\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting\n",
    "\n",
    "Large language models are statistical pattern matching machines, and the idea behind few-shot prompting is that we can\n",
    "give examples in our prompt to help the model tailor its output to what we are looking for. This turns out to be a sort\n",
    "of very simple super power for prompt engineering, and is very helpful when you want to constrain the responses from a\n",
    "model to a specific format. Let's see if it helps us here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"question\":\"What is an assertion?\",\"correct_answer\":\"A boolean expression that returns true or false\",\"incorrect_answer\":\"Another way to say 'assert'\"}\n",
      "\n",
      "Python 3 list question in JSON: \n",
      "{\"question\":\"Lists are ordered collections of data, just like arrays in other languages. What do we call a single element of the list?\",\"correct_answer\":\"Elements\",\"incorrect_answer\":\"Items\"}\n",
      "\n",
      "Python 3 print question in JSON: \n",
      "{\"question\":\"What does 'print()' do?\",\"correct_answer\":\"Prints text to stdout\",\"incorrect_answer\":\"Returns a value\"}\n",
      "\n",
      "Python 3 string question in JSON: \n",
      "{\"question\":\"Strings are just sequences of characters, like the name of this site. What is an escape sequence that puts a space character into a string?\",\"correct_answer\":\"\\ '\\\\n'\",\"incorrect_answer\":\"\\\\t\"}\n",
      "\n",
      "Python 3 boolean question in JSON: \n",
      "{\"question\":\"Booleans are data types that can be True or False. They are not numbers, because they can be only one of two values. What do we call a value that is neither True nor False?\",\"correct_answer\":\"Falsey\",\"incorrect_answer\":\"Falsy\"}\n",
      "\n",
      "Python 3 float question in JSON: \n",
      "{\"question\":\"What does 'float' mean?\",\"correct_answer\":\"A type of number\",\"incorrect_answer\":\"An operation for mathematical functions\"}\n",
      "\n",
      "Python 3 import question in JSON: \n",
      "{\"question\":\"Which statement is true about the 'import' keyword?\",\"correct_answer\":\"Can be used to import files from other folders or modules\",\"incorrect_answer\":\"Is a function that does not take an argument and returns nothing\"}\n"
     ]
    }
   ],
   "source": [
    "# I'm increasing the size of my prompt, but I'm going back to the format I had\n",
    "# previously. I've intentionally done two things here: (a) a macro pattern, where\n",
    "# I indicate I'm looking for a question in JSON and I just vary the topic, and\n",
    "# (b) a format pattern, where I show what I want the output to look like.\n",
    "\n",
    "prompt = \"\"\"Python 3 lambda question in JSON:\n",
    "{\"question\":\"The lambda keyword in python is:\",\"correct_answer\":\"For declaring anonymous functions\",\"incorrect_answer\":\"For mathematical operations\"}\n",
    "\n",
    "Python 3 def question in JSON:\n",
    "{\"question\":\"What does the 'def' keyword do?\",\"correct_answer\":\"Define a function\",\"incorrect_answer\":\"Declare variables\"}\n",
    "\n",
    "Python 3 assert question in JSON: \n",
    "\"\"\"\n",
    "\n",
    "for response in model.create_completion(prompt, max_tokens=2048, stream=True):\n",
    "    result = response[\"choices\"][0]\n",
    "    print(result[\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. Instantly we get basically what I was looking for -- a question on the topic of asserts in python 3. Sometimes when\n",
    "I run this I also get a number of other questions, with the model just continuing the pattern and going through a list\n",
    "of python keywords and topics and giving me output. I don't always want this, as I don't cover all of the topics it\n",
    "might generate text for. Let's tweak this a bit more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"question\":\"The assert keyword is used for\",\"correct_answer\":\"Testing conditions\",\"incorrect_answer\":\"Making changes to the code\"}\n",
      "\n",
      "Python 3 with question in JSON:\n",
      "{\"question\":\"What does the 'with' statement do?\",\"correct_answer\":\"Declare a variable inside of another variable\",\"incorrect_answer\":\"Use functions and variables from another module\"}"
     ]
    }
   ],
   "source": [
    "# Now I'm just adding the topics at the very beginning. I expect that the model\n",
    "# is going to recognize the patterns here, seeing the list of topics, are repeated\n",
    "# in the individual prompts, and that it will follow and just give me results\n",
    "# for the python 3 assert, with, and import keywords.\n",
    "prompt = \"\"\"Topics: lambda, def, assert, with, import.\n",
    "\n",
    "Python 3 lambda question in JSON:\n",
    "{\"question\":\"The lambda keyword in python is:\",\"correct_answer\":\"For declaring anonymous functions\",\"incorrect_answer\":\"For mathematical operations\"}\n",
    "\n",
    "Python 3 def question in JSON:\n",
    "{\"question\":\"What does the 'def' keyword do?\",\"correct_answer\":\"Define a function\",\"incorrect_answer\":\"Declare variables\"}\n",
    "\n",
    "Python 3 assert question in JSON: \n",
    "\"\"\"\n",
    "\n",
    "for response in model.create_completion(prompt, max_tokens=2048, stream=True):\n",
    "    result = response[\"choices\"][0]\n",
    "    print(result[\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, things are getting exciting and I've just about automated my weekend job! I actually just want the JSON\n",
    "results, and sometimes (though maybe not in the case in your notebook if you are following along!) the result doesn't\n",
    "have all of the JSON fields I might want. Remember, everything is tokens and sequences, and the input prompt is a\n",
    "statistical machine, so there are a couple of things we might tweak further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"question\":\"Which of these are the correct assertions in python code?\",\n",
      "\"correct_answer=\"Assertion statements are never executed\",\n",
      "\"incorrect_answer=[\"Assertion statements evaluate to True\", \"Assertion statements evaluate to False\"]\n",
      "},\n",
      "{\n",
      "\"question\":\"The 'with' statement in python is used for:\",\n",
      "\"correct_answer=\"With statement allows us to open files and close files automatically\",\n",
      "\"incorrect_answer=[\"With statement allows us to import modules\", \"With statement allows us to define variables\"]\n",
      "},\n",
      "{\n",
      "\"question\":\"Which of these statements are correct?\",\n",
      "\"correct_answer=['We can use the 'import' keyword to import modules', 'We can import modules using dot operator']\",\n",
      "\"incorrect_answer=[['Importing module is not required in python'], ['We can use dot operator to import modules']]\"},\n",
      "]\n",
      "}"
     ]
    }
   ],
   "source": [
    "# I'm going to include the list of topics at the top, then I'm going to\n",
    "# use some whitespace formatting on the JSON with newlines to see if this\n",
    "# helps increase adherence to the format while keeping the semantics.\n",
    "# everything except the first line of my\n",
    "\n",
    "prompt = \"\"\"\n",
    "{\"python_3_topics\" = [\"lambda\", \"def\", \"assert\", \"with\", \"import\"],questions=[\n",
    "{\n",
    "\"question\":\"The lambda keyword in python is:\",\n",
    "\"correct_answer\":\"For declaring anonymous functions\",\n",
    "\"incorrect_answer\":\"For mathematical operations\"\n",
    "},\n",
    "{\n",
    "\"question\":\"What does the 'def' keyword do?\",\n",
    "\"correct_answer\":\"Define a function\",\n",
    "\"incorrect_answer\":\"Declare variables\"\n",
    "},\n",
    "{\n",
    "\"\"\"\n",
    "\n",
    "for response in model.create_completion(prompt, max_tokens=2048, stream=True):\n",
    "    result = response[\"choices\"][0]\n",
    "    print(result[\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, I think that's pretty solid. What's really cool about this, I think, is that I'm not conversing with the model, or\n",
    "trying to prime it to be an expert. I just started a JSON document and it captured both the meaning of what I was doing\n",
    "-- writing questions with correct and incorrect answers -- and the syntax of what I was doing -- writing well formed\n",
    "JSON. All this on a quantized 13B parameter model!\n",
    "\n",
    "This is a great time to jump into the notebooks and experiment a bit yourself to see this in action. Here are a couple\n",
    "of nice tasks for you to try and practice what you've learned; first, how would you reimplement this code using the\n",
    "llama 2 chat model?, and second, how would you rewrite the prompts so that there were multiple incorrect answers, all in\n",
    "a JSON list of their own? Give these a shot in the labs workspace.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
