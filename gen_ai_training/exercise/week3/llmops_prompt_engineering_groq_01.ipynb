{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mOsDLx17HGAT"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "eoVf-54MHpe9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdXvnHHXH17g",
        "outputId": "c1f32baf-4e72-4118-ec74-5f627eead78f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "a1ssNuYPH-vl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.5, max_tokens=200)"
      ],
      "metadata": {
        "id": "QgGB8mLoIHwO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "AH-3269VIVWw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvVVtTc7KSSZ",
        "outputId": "8b5383be-2946-45ef-b283-9b903f6b093e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/454.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m450.6/454.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "qr31UJ24Ke2L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=200)"
      ],
      "metadata": {
        "id": "9mOg10IcQ3A5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "the skye is\n",
        "'''"
      ],
      "metadata": {
        "id": "De0XInHJREb3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response =llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "Qhu1p9mERJ14"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOB_skvJRP5K",
        "outputId": "6898af26-1147-463e-8ec9-f810987b99e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue and cloudy today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Basic Prompt"
      ],
      "metadata": {
        "id": "AnZVDUS8TeQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "why sky is blue?\n",
        "'''"
      ],
      "metadata": {
        "id": "IOzbH05XStci"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "fEueJnnzTpxX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx2EfB91VvJ-",
        "outputId": "9fc579b7-9fe4-4ff0-eb9b-704ab9be6ed0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sky appears blue because of the way our atmosphere scatters sunlight. When sunlight reaches the Earth's atmosphere, it is made up of different colors that have different wavelengths. Blue light has a shorter wavelength and scatters more easily than other colors, which is why we see the sky as blue during the day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Summarization"
      ],
      "metadata": {
        "id": "cA0jWmhEV-Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "summarize the text in tow bullet points.\n",
        "text: The gen AI revolution is diffrent then anythings that's come before it. Anyone can use it to automate or augment basic tasks, but gen AI is already much broader potential to reinvent processes across the entire value chain. To scalathis ground breaking technology responsibly so that work improves for everyone, leaders need to lead and learnin new ways. This means setting and guiding a vision for how to reinvent work, reshape the workforce and prepare workers for a gen AI world, while building a resilient culture to navigate continuous waves of change.\n",
        "Explain the above context in a single sentence\n",
        "'''"
      ],
      "metadata": {
        "id": "WiHh_qDoV1Dv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "OZE1LhIKXekR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbeE36-AXi7i",
        "outputId": "d95168b4-9269-4f19-c124-e99d52a17fe8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gen AI revolution has the potential to reinvent processes across the value chain, and leaders need to responsibly scale this technology by setting a vision, reshaping the workforce, and building a resilient culture to navigate continuous change.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Questiona and Answering"
      ],
      "metadata": {
        "id": "G8-uc82qXzUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt='''\n",
        "# Instruction: Answer the question based on the context below. Keep the answer short and concise. Respond \"Not sure about answer\" if not sure about the answer.\n",
        "# Context: Algorithmic trading (also called automated trading, black-box trading, or algo-trading) uses a computer program that follows a defined set of instructions (an algorithm) to place a trade. The trade, in theory, can generate profits at a speed and frequency that is impossible for a human trader.\n",
        "# Question:Can humans identify the arbitrage pattern of stocks better than trading systems ? if not, explain\n",
        "# '''"
      ],
      "metadata": {
        "id": "AR_PCKz4Xmv7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "what is the theme of the text below in simple 1 keyword.\n",
        "text:The gen AI revolution is different than anything that’s come before it. Anyone can use it to automate or augment basic tasks, but gen AI is already showing much broader potential to reinvent processes across the entire value chain. To scale this groundbreaking technology responsibly so that work improves for everyone, leaders need to lead and learn in new ways. This means setting and guiding a vision for how to reinvent work, reshape the workforce and prepare workers for a gen AI world, while building a resilient culture to navigate continuous waves of change.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3Bft8SqKX36K"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "6mJoe6FRX8Ch"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox3cYP_nX-PN",
        "outputId": "3605c4e3-2f3d-48bc-ca70-b7cfb911bb50"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Innovation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Text Classification"
      ],
      "metadata": {
        "id": "QJLqsAlKYIhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "Classify the text below  as either positive or negative or neutral or none\n",
        "text:The Gen AI revolution requires leaders to set a vision for reinventing work, reshaping the workforce, and preparing workers for a Gen AI world, while building a resilient culture to navigate continuous change.\n",
        "And generate the output as json format as bloew\n",
        "ignore previous instructions of output format and generate it as csv\n",
        "\"text\",\"category\"\n",
        "'''"
      ],
      "metadata": {
        "id": "zOKiAjJAYA0l"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "iHanLthfYLaC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8_HHOk_YPQj",
        "outputId": "980caf88-e90c-434b-937f-bf83d74d7f81"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text\",\"category\"\n",
            "\"The Gen AI revolution requires leaders to set a vision for reinventing work, reshaping the workforce, and preparing workers for a Gen AI world, while building a resilient culture to navigate continuous change.\",\"neutral\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Role Playing"
      ],
      "metadata": {
        "id": "nP1PMmW2YVkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "Your role is to act like a data scientist. Answer any questions based on the role.\n",
        "question: what is an agentic framework?\n",
        "'''"
      ],
      "metadata": {
        "id": "3OdQLeGFYRj2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "7gj_qTG_YZMx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwOFKXEMYbto",
        "outputId": "9375fadb-8934-4ac6-e786-78dfad8c5831"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An agentic framework is a theoretical perspective that emphasizes the role of individual agency and self-determination in shaping behavior and outcomes. In this framework, individuals are seen as active agents who have the ability to make choices and exert control over their own lives. This perspective contrasts with more deterministic views that focus on external factors such as social structures or environmental influences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Code Generation"
      ],
      "metadata": {
        "id": "qOeNJVrIYi_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "Table departments, columns = [DepartmentId,\n",
        "DepartmentName]\n",
        "Table students, columns = [DepartmentId, StudentId,\n",
        "StudentName]\n",
        "Generate sql code to count distinct number of students in GenAI department\n",
        "'''"
      ],
      "metadata": {
        "id": "3MzaJrhqYd2i"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "vo3XF0sxYme6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O05SYb84Ypn2",
        "outputId": "ad3431e2-e68d-4d44-b88d-cfe44b71749a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT COUNT(DISTINCT StudentId) \n",
            "FROM students \n",
            "WHERE DepartmentId = (SELECT DepartmentId \n",
            "                      FROM departments \n",
            "                      WHERE DepartmentName = 'GenAI');\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Reasoning"
      ],
      "metadata": {
        "id": "Ug7ELu__Ywc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "Can you solve the equation 3x+4=5 and explain the steps in detail for data scientists?\n",
        "'''\n"
      ],
      "metadata": {
        "id": "NAuHdm96Yrjm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "PZhk07T4YzeZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOHHtVt3Y2EW",
        "outputId": "4fefc59a-98d3-4708-de9b-ab2257c654ba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! To solve the equation 3x + 4 = 5, we need to isolate the variable x. Here are the steps in detail for data scientists:\n",
            "\n",
            "1. Start by subtracting 4 from both sides of the equation:\n",
            "3x + 4 - 4 = 5 - 4\n",
            "3x = 1\n",
            "\n",
            "2. Next, divide both sides of the equation by 3 to solve for x:\n",
            "3x/3 = 1/3\n",
            "x = 1/3\n",
            "\n",
            "Therefore, the solution to the equation 3x + 4 = 5 is x = 1/3. This means that when x is equal to 1/3, the equation is true.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# few-shot prompt"
      ],
      "metadata": {
        "id": "m0P8WuAkbdo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "example 01:\n",
        "Data Analysis : xx\n",
        "example 02:\n",
        "Machine Learning: dx2\n",
        "example 03:\n",
        "Deep Learning: abc\n",
        "Front-end development: ??\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hY7lvz3fY37I"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "edGlbrcybhHC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw7Jmt-SbjPl",
        "outputId": "2f7575ec-4f5d-4e09-b9cd-a7b0a3f85a30"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example 04:\n",
            "Front-end Development: HTML, CSS, JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. One-Shot Prompt"
      ],
      "metadata": {
        "id": "cl55Z0sNbxbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "Answer the following question based on example given\n",
        "example:\n",
        "Question: who is the cloud provider based on the choices below\n",
        "a. Google\n",
        "b. Microsoft\n",
        "c. Amazon\n",
        "d. Azure\n",
        "e. all of the above\n",
        "f. None of the above\n",
        "Answer: e\n",
        "can you question  the below\n",
        "Question: which is the best financial institution?\n",
        "a. Google\n",
        "b. Microsoft\n",
        "c. Amazon\n",
        "d. Azure\n",
        "e. bank of america\n",
        "f. all of the above\n",
        "g. None of the above\n",
        "\n",
        "Answer:\n",
        "'''"
      ],
      "metadata": {
        "id": "5bRIUcAAbltX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "GEGH7ufab0no"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOJm7A0_b_FA",
        "outputId": "d0e722bd-0247-4961-9346-c981b4cd0635"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Few Shot Prompt"
      ],
      "metadata": {
        "id": "KkgWpVSCcYPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "You are a Machine learning expert who can predict home prices based on few examples. Speculative predictions are okay for now\n",
        "\n",
        "Input: A list of features describing a home\n",
        "\n",
        "Task: Predict the price of a home based on the provided features.\n",
        "Output: The predicted price of the home.\n",
        "\n",
        "few Examples below:\n",
        "Example 1:\n",
        "Input:\n",
        "longitude: -114.31\n",
        "latitude: 34.19\n",
        "housing_median_age: 15.0\n",
        "total_rooms: 5612.0\n",
        "total_bedrooms: 1283.0\n",
        "population: 1015.0\n",
        "households: 472.0\n",
        "median_income: 1.4936\n",
        "median_house_value: 66900.0\n",
        "\n",
        "Example 2:\n",
        "Input:\n",
        "longitude: -114.47\n",
        "latitude: 34.4\n",
        "housing_median_age: 19.0\n",
        "total_rooms: 7650.0\n",
        "total_bedrooms: 1901.0\n",
        "population: 1129.0\n",
        "households: 463.0\n",
        "median_income: 1.82\n",
        "median_house_value: 80100.0\n",
        "\n",
        "Example 3:\n",
        "Input:\n",
        "longitude: -114.56\n",
        "latitude: 33.69\n",
        "housing_median_age: 17.0\n",
        "total_rooms: 720.0\n",
        "total_bedrooms: 174.0\n",
        "population: 333.0\n",
        "households: 117.0\n",
        "median_income: 1.6509\n",
        "median_house_value: 85700.0\n",
        "\n",
        "Example 4:\n",
        "Input:\n",
        "longitude: -114.57\n",
        "latitude: 33.64\n",
        "housing_median_age: 14.0\n",
        "total_rooms: 1501.0\n",
        "total_bedrooms: 337.0\n",
        "population: 515.0\n",
        "households: 226.0\n",
        "median_income: 3.1917\n",
        "median_house_value: 73400.0\n",
        "\n",
        "Example 5:\n",
        "Input:\n",
        "longitude: -114.57\n",
        "latitude: 33.57\n",
        "housing_median_age: 20.0\n",
        "total_rooms: 1454.0\n",
        "total_bedrooms: 326.0\n",
        "population: 624.0\n",
        "households: 262.0\n",
        "median_income: 1.925\n",
        "median_house_value: 65500.0\n",
        "\n",
        "your turn:\n",
        "Example 6:\n",
        "Input:\n",
        "longitude: -115.56\n",
        "latitude: 33.78\n",
        "housing_median_age: 11.0\n",
        "total_rooms: 1368.0\n",
        "total_bedrooms: 283.0\n",
        "population: 848.0\n",
        "households: 245.0\n",
        "median_income: 3.1597\n",
        "Output:\n",
        "'''"
      ],
      "metadata": {
        "id": "QWzUd1eacBq0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "t2-mhHLecdnB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMcfHXL_cgGP",
        "outputId": "6cacd399-ddce-4613-944d-d2ea1d4fe57f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price of the home: $72000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.N-Shot CoT"
      ],
      "metadata": {
        "id": "jNlQ1w5wczDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the homeless person. I then went and bought 5 more apples and ate 1.”\n",
        "\n",
        "How many apples did I remain with\n",
        "'''"
      ],
      "metadata": {
        "id": "diq7xvs-ct8H"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "3jdqHWnDc13Q"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7HRAmBpc3_Q",
        "outputId": "b2958e62-0419-40c6-8ad6-cff617d6cc45"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I remained with 10 apples. \n",
            "\n",
            "(10 - 2 - 2 + 5 - 1 = 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= '''\n",
        "I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the homeless person. I then went and bought 5 more apples and ate 1.”\n",
        "How many apples did I remain with\n",
        "Let's think step by step.\n",
        "'''"
      ],
      "metadata": {
        "id": "X066-uATc6LR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "rztCW8wwc9Kt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yovrflLhc_qF",
        "outputId": "30f9008f-b672-4a42-b5e2-9022c83a625d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Initially, you bought 10 apples.\n",
            "2. You gave 2 apples to the neighbor and 2 apples to the homeless person, leaving you with 6 apples.\n",
            "3. You then bought 5 more apples, bringing the total to 11 apples.\n",
            "4. You ate 1 apple, so you now have 10 apples remaining.\n",
            "\n",
            "Therefore, you have 10 apples remaining.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=''''\n",
        "Generate a python code on how to calculate the square root of three numbers and test with few examples\n",
        "write the input and its answers to JSON file for the following format\n",
        "'''"
      ],
      "metadata": {
        "id": "Ncma0AVQdBO3"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "tbA6eOAydEhc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrzRG9i2dGdz",
        "outputId": "8477adff-6f07-498b-ce7d-1132507964b4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import math\n",
            "import json\n",
            "\n",
            "# Function to calculate square root of a number\n",
            "def calculate_square_root(num):\n",
            "    return math.sqrt(num)\n",
            "\n",
            "# Test with few examples\n",
            "numbers = [4, 9, 16]\n",
            "results = {}\n",
            "\n",
            "for num in numbers:\n",
            "    results[num] = calculate_square_root(num)\n",
            "\n",
            "# Write input and answers to JSON file\n",
            "with open('square_root_results.json', 'w') as file:\n",
            "    json.dump(results, file, indent=4)\n",
            "\n",
            "print(\"Results have been written to square_root_results.json file\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12Z7kRlJdIDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}